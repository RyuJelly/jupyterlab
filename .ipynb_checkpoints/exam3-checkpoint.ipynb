{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "busNum = '360'\n",
    "key = '%2BjzsSyNtwmcqxUsGnflvs3rW2oceFvhHR8AFkM3ao%2Fw50hwHXgGyPVutXw04uAXvrkoWgkoScvvhlH7jgD4%2FRQ%3D%3D'\n",
    "url1 = 'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?serviceKey='+key+'&strSrch='+busNum\n",
    "savename = 'C:/Temp/businfo.xml'\n",
    "req.urlretrieve(url1, savename)\n",
    "\n",
    "xml = open(savename, 'r', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(xml, features=\"xml\")\n",
    "\n",
    "busRouteId = None\n",
    "for itemList in soup.find_all('itemList') :\n",
    "    busRouteId = itemList.find('busRouteId').string\n",
    "    busRouteNm = itemList.find('busRouteNm').string\n",
    "    if busRouteNm == busNum :\n",
    "        break\n",
    "\n",
    "url2 = 'http://ws.bus.go.kr/api/rest/busRouteInfo/getStaionByRoute?ServiceKey='+key+'&busRouteId='+busRouteId\n",
    "\n",
    "savename = 'C:/Temp/buspos.xml'\n",
    "req.urlretrieve(url2, savename)\n",
    "\n",
    "xml = open(savename, 'r', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(xml, features=\"xml\")\n",
    "\n",
    "busPos = []\n",
    "for itemList in soup.find_all('itemList') :\n",
    "    gpsY = itemList.find('gpsY').string\n",
    "    gpsX = itemList.find('gpsX').string\n",
    "\n",
    "    busPos.append((gpsY, gpsX))\n",
    "\n",
    "print('[ ' + busNum + '번 버스의 운행 위치 ]')\n",
    "if len(busPos) != 0 :\n",
    "    print(busNum + '번 버스 ' + str(len(busPos)) + '대 운행중...')\n",
    "    for lat,lng in busPos :\n",
    "        print(lat+','+lng)\n",
    "else :\n",
    "    print('현재 운행중인 ' + busNum + '번 버스가 없어요...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "key = '796143536a756e69313134667752417a'\n",
    "contentType = 'xml'\n",
    "startIndex = '1'\n",
    "endIndex = '100'\n",
    "url = 'http://openapi.seoul.go.kr:8088/'+key+'/'+contentType+'/LampScpgmtb/'+startIndex+'/'+endIndex+'/'\n",
    "savename = 'C:/Temp/edu.xml'\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, 'r', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(xml, 'xml')\n",
    "\n",
    "pjList = []\n",
    "for itemList in soup.find_all('row') :\n",
    "    up_nm = itemList.find('UP_NM').string\n",
    "    up_nm = '없음' if up_nm is None else up_nm\n",
    "    pgm_nm = itemList.find('PGM_NM').string\n",
    "    pgm_nm = '없음' if pgm_nm is None else pgm_nm\n",
    "    target_nm = itemList.find('TARGET_NM').string\n",
    "    target_nm = '없음' if target_nm is None else target_nm\n",
    "    u_price = itemList.find('U_PRICE').string\n",
    "    u_price = '없음' if u_price is None else u_price\n",
    "    pjList.append((up_nm, pgm_nm, target_nm, u_price))\n",
    "\n",
    "print('[ 서울 청소년 수련관 강좌 리스트 ]')\n",
    "for up_nm,pgm_nm,target_nm,u_price in pjList :\n",
    "    print(up_nm+','+pgm_nm+','+target_nm+','+str(u_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import io\n",
    "\n",
    "key = '796143536a756e69313134667752417a'\n",
    "contentType = 'xml'\n",
    "startIndex = '1'\n",
    "endIndex = '100'\n",
    "date = '20190710'\n",
    "\n",
    "url = 'http://openapi.seoul.go.kr:8088/'+key+'/'+contentType+'/CardSubwayStatsNew/'+startIndex+'/'+endIndex+'/'+date+'/'\n",
    "savename = 'C:/Temp/subway.xml'\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, 'r', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(xml, 'xml')\n",
    "\n",
    "subwayList = []\n",
    "for itemList in soup.find_all('row') :\n",
    "    line_num = itemList.find('LINE_NUM').string\n",
    "    sub_sta_nm = itemList.find('SUB_STA_NM').string\n",
    "    ride_pasgr_num = itemList.find('RIDE_PASGR_NUM').string\n",
    "    alight_pasgr_num = itemList.find('ALIGHT_PASGR_NUM').string\n",
    "    subwayList.append((line_num, sub_sta_nm, ride_pasgr_num, alight_pasgr_num))\n",
    "\n",
    "print('[ 서울시 지하철호선별 역별 승하차 인원 정보 ]')\n",
    "for line_num, sub_sta_nm, ride_pasgr_num, alight_pasgr_num in subwayList :\n",
    "    print(line_num+','+sub_sta_nm+','+ride_pasgr_num+','+alight_pasgr_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import io\n",
    "\n",
    "key = '4WQ7X833TXC370SUTDX4'\n",
    "contentType = 'xml'\n",
    "startIndex = '1'\n",
    "endIndex = '100'\n",
    "\n",
    "url = 'http://ecos.bok.or.kr/api/KeyStatisticList/'+key+'/'+contentType+'/kr/'+startIndex+'/'+endIndex+'/'\n",
    "savename = 'C:/Temp/ecos.xml'\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, 'r', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(xml, 'xml')\n",
    "\n",
    "\n",
    "ecoList = []\n",
    "for itemList in soup.find_all('row') :\n",
    "    class_name = itemList.find('CLASS_NAME').string\n",
    "    class_name = '없음' if class_name is None else class_name\n",
    "    keystat_name = itemList.find('KEYSTAT_NAME').string\n",
    "    keystat_name = '없음' if keystat_name is None else keystat_name\n",
    "    data_value = itemList.find('DATA_VALUE').string\n",
    "    data_value = '없음' if data_value is None else data_value\n",
    "    cycle = itemList.find('CYCLE').string\n",
    "    cycle = '없음' if cycle is None else cycle\n",
    "    unit_name = itemList.find('UNIT_NAME').string\n",
    "    unit_name = '없음' if unit_name is None else unit_name\n",
    "    ecoList.append((class_name, keystat_name, data_value, cycle, unit_name))\n",
    "\n",
    "print('[ 100대 통계 지표 ]')\n",
    "for class_name, keystat_name, data_value, cycle, unit_name in ecoList :\n",
    "    print(class_name+','+keystat_name+','+data_value+','+cycle+','+unit_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "client_secret = 'WrwbQ1l6ZI'\n",
    "\n",
    "query = '치맥'\n",
    "encText = urllib.parse.quote_plus(query)\n",
    "\n",
    "num = 100\n",
    "naver_url = 'https://openapi.naver.com/v1/search/blog.json?query=' + encText + '&display=' + str(num)\n",
    "\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode == 200):\n",
    "    response_body = response.read()\n",
    "    dataList = json.loads(response_body)\n",
    "    count = 1\n",
    "    print('[' + query + '에 대한 네이버 블로그 글 ]')\n",
    "    for data in dataList['items'] :\n",
    "        print (str(count) + ' : ' + data['title'])\n",
    "        print ('[' + data['description'] + ']')\n",
    "        count += 1\n",
    "else:\n",
    "    print('오류 코드 : ' + rescode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "client_secret = 'WrwbQ1l6ZI'\n",
    "query = '치맥'\n",
    "encText = urllib.parse.quote_plus(query)\n",
    "\n",
    "num = 100\n",
    "naver_url = 'https://openapi.naver.com/v1/search/news.json?query=' + encText + '&display=' + str(num)\n",
    "\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode == 200):\n",
    "    response_body = response.read()\n",
    "    dataList = json.loads(response_body)\n",
    "    count = 1\n",
    "    print('[' + query + '에 대한 네이버 뉴스 글 ]')\n",
    "    for data in dataList['items'] :\n",
    "        print (str(count) + ' : ' + data['title'])\n",
    "        print ('[' + data['description'] + ']')\n",
    "        count += 1\n",
    "else:\n",
    "    print('오류 코드 : ' + rescode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "api_key = \"RvnZeIl8ra88reu8fm23m0bST\"\n",
    "api_secret = \"wTRylK94GK2KmhZUnqXonDaIszwAsS6VPvpSsIo6EX5GQLtzQo\"\n",
    "access_token = \"959614462004117506-dkWyZaO8Bz3ZXh73rspWfc1sQz0EnDU\"\n",
    "access_token_secret = \"rxDWfg7uz1yXMTDwijz0x90yWhDAnmOM15R6IgC8kmtTe\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "keyword = '치맥'   \n",
    "search = []   \n",
    "\n",
    "cnt = 1\n",
    "while(cnt <= 10):   \n",
    "    tweets = api.search(q=keyword, count=100)\n",
    "    for tweet in tweets :\n",
    "        search.append(tweet)\n",
    "    cnt += 1\n",
    "\n",
    "data = {}   \n",
    "i = 1   \n",
    "print('[' + keyword + '에 대한 트윗 글 ]')    \n",
    "for tweet in search:\n",
    "    data['text'] = tweet.text   \n",
    "    print(i, \" : \", data)   \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "client_key = '1YWliVkIF7AZI0WoN6ql'\n",
    "client_secret = 'h5iTXTEtRo'\n",
    "query = '치맥'\n",
    "encText = urllib.parse.quote_plus(query)\n",
    "\n",
    "num = 100\n",
    "naver_url = 'https://openapi.naver.com/v1/search/news.json?query=' + encText + '&display=' + str(num)\n",
    "\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode == 200):\n",
    "    response_body = response.read()\n",
    "    dataList = json.loads(response_body)\n",
    "    count = 1\n",
    "    print('[' + query + '에 대한 네이버 뉴스 글 ]')\n",
    "    for data in dataList['items'] :\n",
    "        print (str(count) + ' : ' + data['title'])\n",
    "        print ('[' + data['description'] + ']')\n",
    "        count += 1\n",
    "else:\n",
    "    print('오류 코드 : ' + rescode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
