{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stname = \"유니코\"; stage=20; stavg=95.869\n",
    "print(stname+\"학생은 나이가 \"+str(stage)+\"이고 평균은 \"+str(stavg)+\"입니다\")\n",
    "print(stname, \"학생은 나이가 \", stage, \"이고 평균은 \", stavg, \"입니다\", sep=\"\")\n",
    "print(\"%s학생은 나이가 %d이고 평균은 %.2f입니다\" % (stname, stage, stavg))\n",
    "print(\"{}학생은 나이가 {}이고 평균은 {:.2f}입니다\".format(stname, stage, stavg))\n",
    "print(f\"{stname}학생은 나이가 {stage}이고 평균은 {stavg:.2f}입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = stname+\"학생은 나이가 \"+str(stage)+\"이고 평균은 \"+str(stavg)+\"입니다\"\n",
    "v2 = \"%s학생은 나이가 %d이고 평균은 %.2f입니다\" % (stname, stage, stavg)\n",
    "v3 = \"{}학생은 나이가 {}이고 평균은 {:.2f}입니다\".format(stname, stage, stavg)\n",
    "v4 = f\"{stname}학생은 나이가 {stage}이고 평균은 {stavg:.2f}입니다\"\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "200\n",
      "11\n",
      "OK\n",
      "[ header 정보 ]----------\n",
      "('Server', 'NWS')\n",
      "('Date', 'Wed, 14 Oct 2020 05:21:30 GMT')\n",
      "('Content-Type', 'text/html; charset=UTF-8')\n",
      "('Transfer-Encoding', 'chunked')\n",
      "('Connection', 'close')\n",
      "('Set-Cookie', 'PM_CK_loc=fc96476fb2f2fa144d6679d0756d3b506dbae1a6674bca98007f7014ad0c088d; Expires=Thu, 15 Oct 2020 05:21:30 GMT; Path=/; HttpOnly')\n",
      "('Cache-Control', 'no-cache, no-store, must-revalidate')\n",
      "('Pragma', 'no-cache')\n",
      "('P3P', 'CP=\"CAO DSP CURa ADMa TAIa PSAa OUR LAW STP PHY ONL UNI PUR FIN COM NAV INT DEM STA PRE\"')\n",
      "('X-Frame-Options', 'DENY')\n",
      "('X-XSS-Protection', '1; mode=block')\n",
      "('Strict-Transport-Security', 'max-age=63072000; includeSubdomains')\n",
      "('Referrer-Policy', 'unsafe-url')\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "res = urllib.request.urlopen(\"http://www.naver.com/\")\n",
    "print(type(res))\n",
    "print(res.status)\n",
    "print(res.version)\n",
    "print(res.msg)\n",
    "res_header = res.getheaders()\n",
    "print(\"[ header 정보 ]----------\")\n",
    "for s in res_header :\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x000001C85A659908>\n",
      "[ header 정보 ]----------\n",
      "('Date', 'Wed, 14 Oct 2020 05:26:32 GMT')\n",
      "('Server', 'Apache/2.2.15 (CentOS)')\n",
      "('Content-Length', '461')\n",
      "('Connection', 'close')\n",
      "('Content-Type', 'text/html')\n",
      "[ body 내용 ]-----------\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>Insert title here</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>블럭스타일 태그</h1>\n",
      "<div style=\"background-color:yellow\">테스트입니다1</div>\n",
      "<div>테스트입니다2</div>\n",
      "<div>테스트입니다3</div>\n",
      "<hr>\n",
      "<h1>인라인스타일 태그</h1>\n",
      "<span style=\"background-color:yellow\">테스트입니다1</span>\n",
      "<span>테스트입니다2</span>\n",
      "<span>테스트입니다3</span>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "res = urllib.request.urlopen(\"http://unico2013.dothome.co.kr/crawling/tagstyle.html\")\n",
    "print(res)\n",
    "print(\"[ header 정보 ]----------\")\n",
    "res_header = res.getheaders()\n",
    "for s in res_header :\n",
    "    print(s)\n",
    "print(\"[ body 내용 ]-----------\")\n",
    "#print(res.read())\n",
    "print(res.read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "<class 'http.client.HTTPResponse'>\n",
      "<class 'http.client.HTTPMessage'>\n",
      "https://www.python.org/  페이지의 인코딩 정보 : utf-8\n",
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu\n",
      "===========================================================\n",
      "https://www.daum.net/  페이지의 인코딩 정보 : utf-8\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"ko\" class=\"\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Daum</title>\n",
      "<meta property=\"og:url\" content=\"https://www.daum.net/\">\n",
      "<meta property=\"og:type\" content=\"website\">\n",
      "<meta property=\"og:title\" content=\"Daum\">\n",
      "<meta property=\"og:image\" content=\"//i1.daumcdn.net/svc/image/U03/common_icon/5587C4E4012FCD0001\">\n",
      "<meta property=\"og:description\" content=\"나의 관심 콘텐츠를 가장 즐겁게 볼 수 있는 Daum\">\n",
      "<meta name=\"msapplication-task\" content=\"name=Daum;action-\n",
      "===========================================================\n",
      "https://www.aladin.co.kr/home/welcome.aspx  페이지의 인코딩 정보 : utf-8\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" >\n",
      "<html>\n",
      "  <head>    \n",
      "      <title id=\"Title\">알라딘</title>\n",
      "      <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
      "\t  <meta content=\"Microsoft Visual Studio .NET 7.1\" name=\"GENERATOR\">\n",
      "\t  <meta content=\"C#\" name=\"CODE_LANGUAGE\">\n",
      "\t  <meta content=\"JavaScript\" name=\"vs_defaultClientScript\">\n",
      "\t  <meta content=\"http://schemas.microsoft.com/intellisense/ie5\" name=\"vs_targetSchema\">\n",
      "      <meta http-equiv=\"\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "print(\"===========================================================\")\n",
    "url = 'https://www.python.org/'\n",
    "f = urllib.request.urlopen(url)\n",
    "print(type(f))\n",
    "print(type(f.info()))\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'https://www.daum.net/'\n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'https://www.aladin.co.kr/home/welcome.aspx'\n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ URL 문자열 정보 추출 1 ]\n",
      "타입정보 :  <class 'urllib.parse.ParseResult'>\n",
      "도메인정보 :  movie.daum.net\n",
      "패스정보 :  /moviedb/main\n",
      "쿼리정보 :  movieId=93252\n",
      "스킴정보 :  https\n",
      "포트정보 :  None\n",
      "프래그먼트정보 :  \n",
      "URL 문자열정보 :  https://movie.daum.net/moviedb/main?movieId=93252\n",
      "urllib.parse.ParseResult 객체정보 :  ParseResult(scheme='https', netloc='movie.daum.net', path='/moviedb/main', params='', query='movieId=93252', fragment='')\n",
      "\n",
      "[ URL 문자열 정보 추출 2 ]\n",
      "도메인정보 :  docs.python.org\n",
      "패스정보 :  /3/library/urllib.parse.html\n",
      "쿼리정보 :  \n",
      "스킴정보 :  https\n",
      "포트정보 :  None\n",
      "프래그먼트정보 :  urlparse-result-object\n",
      "URL 문자열정보 :  https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object\n",
      "urllib.parse.ParseResult 객체정보 :  ParseResult(scheme='https', netloc='docs.python.org', path='/3/library/urllib.parse.html', params='', query='', fragment='urlparse-result-object')\n",
      "\n",
      "[ Query문자열 또는 요청 파라미터 인코딩 ]\n",
      "number=12524&type=issue&action=show\n",
      "addr=%EC%84%9C%EC%9A%B8%EC%8B%9C+%EA%B0%95%EB%82%A8%EA%B5%AC+%EC%97%AD%EC%82%BC%EB%8F%99\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlencode\n",
    "print(\"[ URL 문자열 정보 추출 1 ]\")\n",
    "url1 = urlparse('https://movie.daum.net/moviedb/main?movieId=93252')\n",
    "print(\"타입정보 : \",type(url1))\n",
    "print(\"도메인정보 : \",url1.netloc) \n",
    "print(\"패스정보 : \",url1.path)\n",
    "print(\"쿼리정보 : \",url1.query) \n",
    "print(\"스킴정보 : \",url1.scheme)\n",
    "print(\"포트정보 : \",url1.port)\n",
    "print(\"프래그먼트정보 : \",url1.fragment)\n",
    "print(\"URL 문자열정보 : \",url1.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url1)\n",
    "print(\"\\n[ URL 문자열 정보 추출 2 ]\")\n",
    "url2 = urlparse('https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object')\n",
    "print(\"도메인정보 : \",url2.netloc) \n",
    "print(\"패스정보 : \", url2.path)  \n",
    "print(\"쿼리정보 : \",url2.query)\n",
    "print(\"스킴정보 : \",url2.scheme)\n",
    "print(\"포트정보 : \",url2.port)\n",
    "print(\"프래그먼트정보 : \",url2.fragment)\n",
    "print(\"URL 문자열정보 : \",url2.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url2)\n",
    "\n",
    "print(\"\\n[ Query문자열 또는 요청 파라미터 인코딩 ]\")\n",
    "params1 = urlencode({'number': 12524, 'type': 'issue', 'action': 'show'})\n",
    "print(params1)\n",
    "params2 = urlencode({'addr': '서울시 강남구 역삼동'})\n",
    "print(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 인코딩 규칙이 적용된 문자열 : name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "params = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % params)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/get.php?%s\" % params\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 인코딩 규칙이 적용된 문자열 : name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10\n",
      "변환된 바이트 문자열 : b'name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10'\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % data)\n",
    "postdata = data.encode('ascii')\n",
    "print(\"변환된 바이트 문자열 : %s\" % postdata)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/post.php\"\n",
    "with urllib.request.urlopen(url, postdata) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x000001C85A6EDB48>\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "postdata = data.encode('ascii')\n",
    "req = urllib.request.Request(url='http://unico2013.dothome.co.kr/crawling/post.php',\n",
    "            data=postdata)\n",
    "print(req)\n",
    "with urllib.request.urlopen(req) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>테스트</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>웹 크롤링을 테스트 합니다.</h1>\n",
      "</body>\n",
      "</html>\n",
      "----------------------------------------------------------\n",
      "<class 'requests.models.Response'>\n",
      "응답된 콘텐츠가 없어요\n",
      "----------------------------------------------------------\n",
      "<class 'requests.models.Response'>\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 백도이고 나이는 12이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.request('get', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('head', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('post', 'http://unico2013.dothome.co.kr/crawling/post.php', data= {'name':'백도', 'age' : 12})\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'Date': 'Wed, 14 Oct 2020 06:08:16 GMT', 'Server': 'Apache/2.2.15 (CentOS)', 'Content-Length': '164', 'Connection': 'close', 'Content-Type': 'text/html'}\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>테스트</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>웹 크롤링을 테스트 합니다.</h1>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'Date': 'Wed, 14 Oct 2020 06:10:42 GMT', 'Server': 'Apache/2.2.15 (CentOS)', 'Connection': 'close', 'Content-Type': 'text/html'}\n",
      "응답된 콘텐츠가 없어요\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.head('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key2=value2\n",
      "------------------------------------\n",
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key2=value2&key2=value3\n",
      "------------------------------------\n",
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key2=value2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "dicdata = {'key1': 'value1', 'key2': 'value2'}\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "dicdata = {'key1': 'value1', 'key2': ['value2', 'value3']}\n",
    "r = requests.request('GET', urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "tupledata = [('key1', 'value1'), ('key2', 'value2')]\n",
    "r = requests.get(urlstr, params=tupledata)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : ì´ë¦ê³¼ ëì´ë¥¼ ì ë¬í´ ì£¼ì¸ì!!</h1>   </body>\n",
      "</html>\n",
      "------------------------------------\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름과 나이를 전달해 주세요!!</h1>   </body>\n",
      "</html>\n",
      "------------------------------------\n",
      "b'\\xef\\xbb\\xbf<!DOCTYPE html>\\r\\n<html>\\r\\n  <head>\\r\\n    <meta charset=\"utf-8\">\\r\\n    <title>POST TEST</title>\\r\\n  </head>\\r\\n  <body>\\r\\n   <h1>GET : \\xec\\x9d\\xb4\\xeb\\xa6\\x84\\xea\\xb3\\xbc \\xeb\\x82\\x98\\xec\\x9d\\xb4\\xeb\\xa5\\xbc \\xec\\xa0\\x84\\xeb\\x8b\\xac\\xed\\x95\\xb4 \\xec\\xa3\\xbc\\xec\\x84\\xb8\\xec\\x9a\\x94!!</h1>   </body>\\r\\n</html>'\n",
      "------------------------------------\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름과 나이를 전달해 주세요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr)\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "r.encoding = 'utf-8'\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "print(r.content)\n",
    "print('------------------------------------')\n",
    "print(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/image/flower.jpg')\n",
    "i = Image.open(BytesIO(r.content))\n",
    "print(type(i))\n",
    "i.save(\"c:/Temp/test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <title>Test BeautifulSoup</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>테스트</h1>\n",
    "    </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Test BeautifulSoup\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p align=\"center\">\n",
      "   P태그의 컨텐트\n",
      "  </p>\n",
      "  <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\"/>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Test BeautifulSoup</title>\n",
      "</head>\n",
      "<body>\n",
      "<p align=\"center\">P태그의 컨텐트</p>\n",
      "<img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\"/>\n",
      "</body>\n",
      "</html> \n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(bs.prettify())\n",
    "print(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'> : <title>Test BeautifulSoup</title>\n",
      "<class 'str'> : title\n",
      "<class 'bs4.element.NavigableString'> : Test BeautifulSoup\n",
      "-------------------------\n",
      "<class 'str'> : center\n",
      "<class 'str'> : http://unico2013.dothome.co.kr/image/flower.jpg\n",
      "<class 'dict'> : {'src': 'http://unico2013.dothome.co.kr/image/flower.jpg', 'width': '300'}\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.title), ':', bs.title)\n",
    "print(type(bs.title.name), ':', bs.title.name)\n",
    "print(type(bs.title.string), ':', bs.title.string)\n",
    "print('-------------------------')\n",
    "print(type(bs.p['align']), ':', bs.p['align'])\n",
    "print(type(bs.img['src']), ':', bs.img['src'])\n",
    "print(type(bs.img.attrs), ':', bs.img.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ string 속성 ]\n",
      "<class 'bs4.element.NavigableString'> : P태그의 컨텐트\n",
      "<class 'NoneType'> : None\n",
      "<class 'NoneType'> : None\n",
      "<class 'bs4.element.NavigableString'> : 강조\n",
      "[ text 속성 ]\n",
      "<class 'str'> : P태그의 컨텐트\n",
      "<class 'str'> : \n",
      "테스트1강조\n",
      "테스트2\n",
      "테스트3\n",
      "\n",
      "<class 'str'> : 테스트1강조\n",
      "<class 'str'> : 강조\n",
      "[ contents 속성 ]\n",
      "<class 'list'> : ['P태그의 컨텐트']\n",
      "<class 'list'> : ['\\n', <li>테스트1<strong>강조</strong></li>, '\\n', <li>테스트2</li>, '\\n', <li>테스트3</li>, '\\n']\n",
      "<class 'list'> : ['테스트1', <strong>강조</strong>]\n",
      "<class 'list'> : ['강조']\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(\"[ string 속성 ]\")\n",
    "print(type(bs.p.string), ':', bs.p.string)\n",
    "print(type(bs.ul.string), ':', bs.ul.string)\n",
    "print(type(bs.ul.li.string), ':', bs.ul.li.string)\n",
    "print(type(bs.ul.li.strong.string), ':', bs.ul.li.strong.string)\n",
    "print(\"[ text 속성 ]\")\n",
    "print(type(bs.p.text), ':', bs.p.text)\n",
    "print(type(bs.ul.text), ':', bs.ul.text)\n",
    "print(type(bs.ul.li.text), ':', bs.ul.li.text)\n",
    "print(type(bs.ul.li.strong.text), ':', bs.ul.li.strong.text)\n",
    "print(\"[ contents 속성 ]\")\n",
    "print(type(bs.p.contents), ':', bs.p.contents)\n",
    "print(type(bs.ul.contents), ':', bs.ul.contents)\n",
    "print(type(bs.ul.li.contents), ':', bs.ul.li.contents)\n",
    "print(type(bs.ul.li.strong.contents), ':', bs.ul.li.strong.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.ResultSet'>\n",
      "---------------------------------\n",
      "<title>Test BeautifulSoup</title>\n",
      "<p align=\"center\"> text contents </p>\n",
      "<img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\"/>\n",
      "---------------------------------\n",
      "[<p align=\"center\"> text contents </p>, <p align=\"right\">  text contents 2 </p>, <p align=\"left\">   text contents 3 </p>, <p>text contents 4</p>]\n",
      "<class 'bs4.element.ResultSet'>\n",
      "----------------\n",
      "<p align=\"center\"> text contents </p>\n",
      "<p align=\"right\">  text contents 2 </p>\n",
      "<p align=\"left\">   text contents 3 </p>\n",
      "<p>text contents 4</p>\n"
     ]
    }
   ],
   "source": [
    "html_doc=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\">  text contents 2 </p>\n",
    "     <p align=\"left\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "     <div>\n",
    "       <p>text contents 4</p> \n",
    "     </div>\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.find('p')))\n",
    "print(type(bs.find_all('p')))\n",
    "print(\"---------------------------------\")\n",
    "print(bs.find('title'))\n",
    "print(bs.find('p'))\n",
    "print(bs.find('img'))\n",
    "print(\"---------------------------------\")\n",
    "ptags = bs.find_all('p')\n",
    "print(ptags)\n",
    "print(type(ptags))\n",
    "print(\"----------------\")\n",
    "for tag in ptags :\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\"> text contents </p>\n",
      "<p align=\"right\" class=\"myp\">  text contents 2 </p>\n",
      "<p a=\"b\" align=\"left\">   text contents 3 </p>\n",
      "-------------------------------------\n",
      "<p align=\"center\"> text contents </p>\n",
      "<p align=\"right\" class=\"myp\">  text contents 2 </p>\n",
      "<p a=\"b\" align=\"left\">   text contents 3 </p>\n"
     ]
    }
   ],
   "source": [
    "html=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\" class=\"myp\">  text contents 2 </p>\n",
    "     <p align=\"left\" a=\"b\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.find('p', align=\"center\"))\n",
    "print(bs.find('p', class_=\"myp\"))\n",
    "print(bs.find('p', align=\"left\"))\n",
    "print(\"-------------------------------------\")\n",
    "print(bs.find('p', attrs={\"align\":\"center\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"right\", \"class\":\"myp\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"left\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "==============================\n",
      "<class 'bs4.element.ResultSet'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<h1>태그의 갯수 : 1 \n",
      "f_subtitle이라는 id 속성을 갖는 태그 갯수 : 1 \n",
      "subtitle이라는 class 속성을 갖는 태그 갯수 : 2 \n",
      "aside 태그의 <h2> 자식 태그 갯수 : 1 \n",
      "src 속성을 갖는 태그 갯수 : 1 \n",
      "CSS 선택자 학습\n",
      "------------------------------\n",
      "교육과정 소개\n",
      "------------------------------\n",
      "웹 클라이언트 기술\n",
      "학습 순서(수집)\n",
      "------------------------------\n",
      "학습 순서(수집)\n",
      "------------------------------\n",
      "https://www.python.org/static/img/python-logo.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req = requests.get('http://unico2013.dothome.co.kr/crawling/exercise_css.html')\n",
    "html = req.content\n",
    "print(type(html))\n",
    "html = html.decode('utf-8')\n",
    "#print(html)\n",
    "print(\"==============================\")\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "title = bs.select('h1')\n",
    "title1 = bs.select('#f_subtitle')\n",
    "title2 = bs.select('.subtitle')\n",
    "title3 = bs.select('aside > h2')\n",
    "img = bs.select('[src]')\n",
    "print(type(title))\n",
    "print(type(title[0]))\n",
    "print(\"<h1>태그의 갯수 : %d \" %len(title))\n",
    "print(\"f_subtitle이라는 id 속성을 갖는 태그 갯수 : %d \" %len(title1))\n",
    "print(\"subtitle이라는 class 속성을 갖는 태그 갯수 : %d \" %len(title2))\n",
    "print(\"aside 태그의 <h2> 자식 태그 갯수 : %d \" %len(title3))\n",
    "print(\"src 속성을 갖는 태그 갯수 : %d \" %len(img))\n",
    "\n",
    "for content in title:\n",
    "    print(content.string)\n",
    "print(\"------------------------------\")\n",
    "for content in title1:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title2:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title3:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in img:\n",
    "   print(content[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화 제목 : 뮬란\n",
      "평점 : 5\n",
      "리뷰글 : 일그러진 PC가 망친 또 하나의 작품. 입체성을 잃은 뮬란은 양산형 무협지의 흔한 천재 주인공으로 전락했고, 모든 주변 인들은 단지 성별에 매여 타고난 천재의 앞길을 가로막는 어리석은 장님들이 되어버렸다. 디즈니는 무엇이 과거의 명작을 만들었는지 다시 돌아봐야만 한다. \n",
      "-----------------------------------------\n",
      "영화 제목 : 죽지않는 인간들의 밤\n",
      "평점 : 10\n",
      "리뷰글 : 깨알재미~잼있어요 양동근님 ㅋㅋ 너무 웃겨 죽는줄 \n",
      "-----------------------------------------\n",
      "영화 제목 : 돌멩이\n",
      "평점 : 10\n",
      "리뷰글 : 정말 석구의 삶을 보니 먹먹해지더라고요..그 와중에 우리 삶을 포기하지않고 지켜주시는 분이 생각났습니다.. 너무나 깊은 울림이 있는영화감사합니다 ㅜㅜ 재미있게봤습니다!!^^ \n",
      "-----------------------------------------\n",
      "영화 제목 : 에브리타임 룩 앳 유\n",
      "평점 : 10\n",
      "리뷰글 : 독일판 비포선라이즈같은 영화.개인적으로 이 영화가 더 좋네요.마음이 간질간질,몽글몽글해지는 영화.다른 독일 영화도 보고싶어지네요. \n",
      "-----------------------------------------\n",
      "영화 제목 : 죽지않는 인간들의 밤\n",
      "평점 : 8\n",
      "리뷰글 : 호불호가 있는 영화 .병맛 좋아하면 추천.. 후반부 양동근 나올때마다 피식피식 웃엇어요 ㅎ \n",
      "-----------------------------------------\n",
      "영화 제목 : 애프터: 그 후\n",
      "평점 : 6\n",
      "리뷰글 : 1의 느낌이 더 좋았습니다. \n",
      "-----------------------------------------\n",
      "영화 제목 : 폰조\n",
      "평점 : 2\n",
      "리뷰글 : 범죄자 치매 걸린 영화는 도대체 왜 만드는건지.배우들의 연기력을 논하기조차 귀찮은 영화.영화보다가 30분간이상 자긴 첨이네요. \n",
      "-----------------------------------------\n",
      "영화 제목 : 미녀는 괴로워\n",
      "평점 : 10\n",
      "리뷰글 : 20대 초반에 영화를 보고 30대 중반에 영화를 다시보니 정말 잘 만든 영화라는 생각이 드네요. 못보신분들은 꼭 보시길 추천 드립니다. \n",
      "-----------------------------------------\n",
      "영화 제목 : 죽지않는 인간들의 밤\n",
      "평점 : 1\n",
      "리뷰글 : B급 영화지만 B급영화의 참신함이 없다.화면전환없이 계속되는 지루한 연출,내용흐름 방해하는 쓸데없는 장면,후반에 가니 배우들 연기들까지 싫어진다.대한민국에 눈먼 자본이 많다는걸 이 영화로 다시 확인했다. \n",
      "-----------------------------------------\n",
      "영화 제목 : 소리도 없이\n",
      "평점 : 1\n",
      "리뷰글 : 설정마저도 진부하다. \n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page=1')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.select('.movie')\n",
    "points = soup.select('td.title > div > em')\n",
    "reviews = soup.select('td.title')\n",
    "movie_title = []\n",
    "movie_point = []\n",
    "movie_review = [] \n",
    "\n",
    "for dom in titles:\n",
    "    movie_title.append(dom.text)\n",
    "for dom in points:\n",
    "    movie_point.append(dom.text)\n",
    "for dom in reviews:\n",
    "    content = dom.contents[6] \n",
    "    content=re.sub(\"신고\", '', content)\n",
    "    content=re.sub(\"[\\n\\t]\", '', content)    \n",
    "    movie_review.append(content)\n",
    "commentLength = len(movie_title)   \n",
    "for i in range(commentLength):\n",
    "    print(\"영화 제목 : \" + movie_title[i])\n",
    "    print(\"평점 : \" + movie_point[i])\n",
    "    print(\"리뷰글 : \" + movie_review[i])\n",
    "    print(\"-----------------------------------------\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "for n in range(1,31):\n",
    "    req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page='+str(n))\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    titles = soup.select('.movie' )\n",
    "    points = soup.select('td.title > div > em')\n",
    "    reviews = soup.select('td.title')\n",
    "    movie_title = []\n",
    "    movie_point = []\n",
    "    movie_review = [] \n",
    "    for dom in titles:\n",
    "        movie_title.append(dom.text)\n",
    "    for dom in points:\n",
    "        movie_point.append(dom.text)\n",
    "    for dom in reviews:\n",
    "        content = dom.contents[6]\n",
    "        content=re.sub(\"신고\", '', content)\n",
    "        content=re.sub(\"[\\n\\t]\", '', content)\n",
    "        movie_review.append(content)\n",
    "\n",
    "    commentLength = len(movie_title)   \n",
    "    for i in range(commentLength):\n",
    "        print(movie_point[i] + \"\\t\"+movie_title[i]+\"\\t\"+movie_review[i])\n",
    "    print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리는한팀', '30일후', '아빠는 N살', '공작일보 工作日报', '산군대잔치', '88한 인생', '하임의 서재', '신과 인간', '카나와 초나의 독일', '서폿저택에 어서오세요', '미줌툰', '모두의 미아씨', '좋아하는거 참으면 병나요!', '아오링도쿄', '낮잠 자는 사람들', '겨까게 사랑한다', '고등학교 수감기록', '마왕이 되는 방법', '자체공강', '솔직히 말해서', '너의 여집합', '신혼좀비', '잘먹는 가', '가족같은회사']\n",
      "['어느 가족 이야기', '미래를 알게된 남자', '아빠 4컷 그림일기', '보부장의 상해 살이', '강아지 산군의 일상', '팔팔한 커플 이야기', '비블리오 판타지', '신과 인간의 이야기', '독일 생존기', '서폿만 사는 저택', '미국 줌마의 일상', '미아씨의 매일매일', '좋아하는건 못참아', '도쿄 시트콤', '지하창작인밀착일상툰', '반려묘와자취라이프', '고삼은 존버한다', '자유연재', '대학물인척하는 만화', '로맨스판타지개그만화', '네가 없는 세상', '러브 코믹 호러', '먹는게 낙인 가족들', '완결']\n",
      "['8.57', '9.57', '9.90', '9.18', '9.85', '9.16', '9.89', '9.88', '9.87', '9.85', '9.84', '9.19', '9.68', '9.82', '9.90', '9.32', '9.77', '9.82', '9.87', '9.73', '9.82', '9.89', '9.70', '9.86']\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "data = urllib.request.urlopen('https://comic.naver.com/genre/bestChallenge.nhn')\n",
    "bs = BeautifulSoup(data, 'html.parser')\n",
    "title = []\n",
    "summary = []\n",
    "rating = []\n",
    "titleList = bs.select('.challengeTitle > a')\n",
    "for titleDom in titleList:\n",
    "\ttitle.append(titleDom.string.strip())\n",
    "summaryList = bs.select('.summary')\n",
    "for summaryDom in summaryList:\n",
    "\tsummary.append(summaryDom.text.strip())\n",
    "ratingList = bs.select('.rating_type > strong')\n",
    "for ratingDom in ratingList:\n",
    "\trating.append(ratingDom.get_text(strip=True))\n",
    "print(title)\n",
    "print(summary)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "title = []\n",
    "summary = []\n",
    "rating = []\n",
    "for n in range(1,31):\n",
    "\tdata = urllib.request.urlopen('https://comic.naver.com/genre/bestChallenge.nhn?&page='+str(n))\n",
    "\tbs = BeautifulSoup(data, 'html.parser')\n",
    "\ttitleList = bs.select('.challengeTitle > a')\t\n",
    "\tfor titleDom in titleList:\n",
    "\t\ttitle.append(titleDom.string.strip())\n",
    "\n",
    "\tsummaryList = bs.select('.summary')\t\n",
    "\tfor summaryDom in summaryList:\n",
    "\t\tsummary.append(summaryDom.text.strip())\n",
    "\n",
    "\tratingList = bs.select('.rating_type > strong')\t\n",
    "\tfor ratingDom in ratingList:\n",
    "\t\trating.append(ratingDom.get_text(strip=True))\n",
    "print(title)\n",
    "print(summary)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 도서 제목 --\n",
      "['Do it! 점프 투 파이썬', '혼자 공부하는 파이썬', '이것이 취업을 위한 코딩 테스트다 with 파이썬 ', '핸즈온 머신러닝', '밑바닥부터 시작하는 딥러닝 ', '파이썬 알고리즘 인터뷰', '파이썬 for Beginner', '파이썬 증권 데이터 분석 ', '모두의 데이터 분석 with 파이썬', '파이썬 머신러닝 완벽 가이드', '밑바닥부터 시작하는 딥러닝 2', 'AWS 머신러닝 마스터하기', '생명정보학 알고리즘 ', 'Do it! 첫 파이썬', 'Do it! 점프 투 파이썬 + Do it! 첫 파이썬 ', 'Do it! 점프 투 파이썬 + 딥러닝 입문', 'Do it! 파이썬 생활 프로그래밍', 'Do it! 점프 투 파이썬 + Do it! 파이썬 생활 프로그래밍', '모두의 인공지능 기초 수학', 'Do it! 자료구조와 함께 배우는 알고리즘 입문 : 파이썬 편']\n",
      "-- 도서 링크 URL --\n",
      "['/Product/Goods/74419916?OzSrank=1', '/Product/Goods/74269975?OzSrank=2', '/Product/Goods/91433923?OzSrank=3', '/Product/Goods/89959711?OzSrank=4', '/Product/Goods/34970929?OzSrank=5', '/Product/Goods/91084402?OzSrank=6', '/Product/Goods/83849188?OzSrank=7', '/Product/Goods/90578506?OzSrank=8', '/Product/Goods/72227684?OzSrank=9', '/Product/Goods/87044746?OzSrank=10', '/Product/Goods/72173703?OzSrank=11', '/Product/Goods/93737160?OzSrank=12', '/Product/Goods/93763052?OzSrank=13', '/Product/Goods/89904189?OzSrank=14', '/Product/Goods/91446188?OzSrank=15', '/Product/Goods/79672557?OzSrank=16', '/Product/Goods/91437485?OzSrank=17', '/Product/Goods/91446225?OzSrank=18', '/Product/Goods/91358533?OzSrank=19', '/Product/Goods/91219874?OzSrank=20']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "title = []\n",
    "link = []\n",
    "urlstr = 'http://www.yes24.com/SearchCorner/Search?domain=BOOK&query=python'\n",
    "r = requests.get(urlstr)\n",
    "#r.encoding = \"utf-8\"\n",
    "bs = BeautifulSoup(r.text, 'html.parser')\n",
    "titleList = bs.select('p.goods_name.goods_icon > a > strong')\n",
    "linklList = bs.select('p.goods_name.goods_icon > a')\n",
    "\n",
    "for titleDom in titleList:\n",
    "\ttitle.append(titleDom.string)\n",
    "for linkDom in linklList:\n",
    "\tlink.append(linkDom[\"href\"])\n",
    "\n",
    "print(\"-- 도서 제목 --\")\n",
    "print(title)\n",
    "print(\"-- 도서 링크 URL --\")\n",
    "print(link)\n",
    "with open('C:/Temp/booklink.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "    f.write('booktitle,booklink\\n')  \n",
    "    for i in range(len(title)):\n",
    "        f.write(title[i]+\",\"+link[i]+'\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'서울': ['10~20', '10~20', '10~20', '10~20', '10~21', '10~21', '11~19', '11~19', '11~18', '11~18', '8~17', '7~18', '9~19'], '인천': ['11~19', '11~19', '12~19', '12~19', '11~19', '11~19', '13~19', '13~19', '13~18', '13~18', '9~17', '9~18', '10~18'], '수원': ['8~20', '8~20', '8~20', '8~20', '8~21', '8~21', '10~19', '10~19', '10~19', '10~19', '8~18', '6~19', '8~20'], '파주': ['5~19', '5~19', '6~20', '6~20', '5~20', '5~20', '7~19', '7~19', '7~19', '7~19', '6~19', '5~19', '5~19'], '이천': ['5~20', '5~20', '6~20', '6~20', '5~20', '5~20', '7~19', '7~19', '8~20', '8~20', '7~18', '6~19', '5~19'], '평택': ['7~20', '7~20', '8~20', '8~20', '7~20', '7~20', '9~20', '9~20', '10~19', '10~19', '9~18', '8~19', '8~20'], '춘천': ['5~20', '5~20', '6~20', '6~20', '6~20', '6~20', '8~17', '8~17', '10~18', '10~18', '5~15', '4~16', '6~17'], '원주': ['6~19', '6~19', '7~19', '7~19', '7~20', '7~20', '9~18', '9~18', '10~18', '10~18', '5~16', '4~17', '6~18'], '강릉': ['10~21', '10~21', '11~20', '11~20', '11~20', '11~20', '12~20', '12~20', '13~19', '13~19', '9~18', '9~17', '11~19'], '대전': ['8~20', '8~20', '9~21', '9~21', '8~21', '8~21', '11~19', '11~19', '11~20', '11~20', '8~18', '6~18', '9~19'], '세종': ['7~20', '7~20', '7~20', '7~20', '6~20', '6~20', '9~18', '9~18', '11~19', '11~19', '6~17', '5~18', '7~19'], '홍성': ['5~19', '5~19', '7~20', '7~20', '6~20', '6~20', '9~18', '9~18', '10~18', '10~18', '6~17', '5~18', '7~19'], '청주': ['8~20', '8~20', '9~20', '9~20', '8~21', '8~21', '11~19', '11~19', '12~19', '12~19', '8~18', '6~18', '9~19'], '충주': ['5~19', '5~19', '6~19', '6~19', '6~20', '6~20', '8~18', '8~18', '9~18', '9~18', '5~16', '4~17', '6~18'], '영동': ['4~21', '4~21', '6~20', '6~20', '5~21', '5~21', '8~19', '8~19', '10~18', '10~18', '5~17', '4~18', '6~19'], '광주': ['10~21', '10~21', '11~21', '11~21', '9~22', '9~22', '12~20', '12~20', '12~20', '12~20', '10~18', '8~19', '10~20'], '목포': ['11~20', '11~20', '13~20', '13~20', '11~21', '11~21', '13~20', '13~20', '14~20', '14~20', '12~18', '11~18', '12~20'], '여수': ['14~21', '14~21', '15~21', '15~21', '14~20', '14~20', '15~20', '15~20', '15~21', '15~21', '13~19', '12~19', '14~20'], '순천': ['10~22', '10~22', '12~23', '12~23', '9~23', '9~23', '13~21', '13~21', '13~21', '13~21', '10~19', '9~21', '11~21'], '광양': ['12~22', '12~22', '13~22', '13~22', '11~22', '11~22', '13~21', '13~21', '13~22', '13~22', '10~21', '9~20', '10~20'], '나주': ['7~22', '7~22', '9~22', '9~22', '6~22', '6~22', '10~21', '10~21', '11~20', '11~20', '8~18', '6~19', '9~20'], '전주': ['8~21', '8~21', '9~21', '9~21', '9~21', '9~21', '11~20', '11~20', '11~19', '11~19', '8~18', '7~19', '9~21'], '군산': ['8~20', '8~20', '9~20', '9~20', '9~21', '9~21', '11~19', '11~19', '11~20', '11~20', '8~18', '7~18', '9~19'], '정읍': ['8~20', '8~20', '9~21', '9~21', '9~21', '9~21', '10~19', '10~19', '10~20', '10~20', '7~18', '7~19', '8~20'], '남원': ['7~21', '7~21', '9~21', '9~21', '8~21', '8~21', '9~19', '9~19', '9~19', '9~19', '7~18', '6~19', '8~20'], '고창': ['8~21', '8~21', '9~21', '9~21', '9~21', '9~21', '10~20', '10~20', '10~20', '10~20', '8~17', '7~18', '8~19'], '무주': ['5~20', '5~20', '6~19', '6~19', '5~20', '5~20', '8~18', '8~18', '8~18', '8~18', '5~17', '4~17', '6~19'], '부산': ['13~22', '13~22', '14~22', '14~22', '13~22', '13~22', '15~22', '15~22', '15~22', '15~22', '12~20', '11~21', '13~22'], '울산': ['11~21', '11~21', '12~21', '12~21', '11~20', '11~20', '13~21', '13~21', '13~21', '13~21', '10~19', '9~19', '10~21'], '창원': ['11~21', '11~21', '12~21', '12~21', '11~21', '11~21', '13~21', '13~21', '14~22', '14~22', '11~19', '10~20', '12~22'], '진주': ['8~22', '8~22', '9~22', '9~22', '7~22', '7~22', '10~21', '10~21', '11~22', '11~22', '7~20', '6~20', '7~21'], '거창': ['5~21', '5~21', '6~21', '6~21', '5~21', '5~21', '8~19', '8~19', '9~20', '9~20', '5~18', '4~19', '5~20'], '통영': ['13~22', '13~22', '13~22', '13~22', '12~22', '12~22', '15~22', '15~22', '15~22', '15~22', '12~20', '11~20', '14~21'], '대구': ['8~21', '8~21', '10~21', '10~21', '8~22', '8~22', '11~20', '11~20', '13~21', '13~21', '8~19', '8~20', '9~20'], '안동': ['5~20', '5~20', '6~20', '6~20', '5~20', '5~20', '9~19', '9~19', '9~19', '9~19', '5~17', '4~18', '6~19'], '포항': ['11~21', '11~21', '13~20', '13~20', '12~20', '12~20', '14~20', '14~20', '14~21', '14~21', '10~19', '10~19', '12~20'], '경주': ['7~22', '7~22', '10~22', '10~22', '9~21', '9~21', '10~20', '10~20', '11~21', '11~21', '7~19', '6~19', '8~19'], '울진': ['8~20', '8~20', '10~20', '10~20', '10~19', '10~19', '12~19', '12~19', '12~19', '12~19', '9~17', '9~17', '9~19'], '울릉도': ['14~19', '14~19', '14~19', '14~19', '14~18', '14~18', '14~19', '14~19', '15~19', '15~19', '12~16', '12~16', '13~17'], '제주': ['15~21', '15~21', '16~20', '16~20', '14~21', '14~21', '16~21', '16~21', '17~20', '17~20', '15~19', '14~19', '14~20'], '서귀포': ['15~21', '15~21', '16~21', '16~21', '15~22', '15~22', '16~22', '16~22', '16~22', '16~22', '14~20', '13~21', '15~21']}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import io\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=108\"\n",
    "savename = \"C:/Temp/forecast.xml\"\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, \"r\", encoding=\"utf-8\").read()\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "\n",
    "info = {}\n",
    "for location in soup.find_all(\"location\"):\n",
    "    loc = location.find('city').string\n",
    "    min_w = location.find_all('tmn')\n",
    "    max_w = location.find_all('tmx')\n",
    "    weather = [a.string+\"~\"+b.string for a, b in zip(min_w, max_w)]\n",
    "\n",
    "    if not (loc in info):\n",
    "        info[loc] = []\n",
    "    for data in weather:\n",
    "        info[loc].append(data)\n",
    "print(info)\n",
    "\n",
    "with open('C:/Temp/forecast.txt', \"wt\", encoding=\"utf-8\") as f:\n",
    "    for loc in sorted(info.keys()):\n",
    "        f.write(str(loc)+'\\n')\n",
    "        for name in info[loc]:\n",
    "            f.write('\\t'+str(name)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "브라우저 요청입니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "\n",
    "#User-Agent를 조작하는 경우 \n",
    "hdr = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '+ \n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.80 Safari/537.36'}\n",
    "\n",
    "req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php', headers = hdr)\n",
    "#req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php')\n",
    "data = urllib.request.urlopen(req).read()\n",
    "#page = data.decode('utf-8', 'ignore')\n",
    "res_content = json.loads(data)\n",
    "\n",
    "print(res_content[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
